{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for text classification in Python\n",
    "\n",
    "https://www.annytab.com/naive-bayes-for-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import re\n",
    "import string\n",
    "import nltk.stem\n",
    "\n",
    "# Download WordNetLemmatizer\n",
    "#nltk.download()\n",
    "\n",
    "\n",
    "# Variabes\n",
    "QUOTES = re.compile(r'(writes in|writes:|wrote:|says:|said:|^In article|^Quoted from|^\\||^>)')\n",
    "\n",
    "# Preprocess data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \n",
    "    # Create a stemmer/lemmatizer\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    #lemmer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        # Remove header\n",
    "        _, _, data[i] = data[i].partition('\\n\\n')\n",
    "        \n",
    "        \n",
    "        # Remove footer\n",
    "        lines = data[i].strip().split('\\n')\n",
    "        for line_num in range(len(lines) - 1, -1, -1):\n",
    "            line = lines[line_num]\n",
    "            if line.strip().strip('-') == '':\n",
    "                break\n",
    "        if line_num > 0:\n",
    "            data[i] = '\\n'.join(lines[:line_num])\n",
    "        \n",
    "        \n",
    "        # Remove quotes\n",
    "        data[i] = '\\n'.join([line for line in data[i].split('\\n') if not QUOTES.search(line)])\n",
    "        \n",
    "        # Remove punctuation (!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~)\n",
    "        data[i] = data[i].translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Remove digits\n",
    "        data[i] = re.sub('\\d', '', data[i])\n",
    "        \n",
    "        \n",
    "        # Stem words\n",
    "        data[i] = ' '.join([stemmer.stem(word) for word in data[i].split()])\n",
    "        #data[i] = ' '.join([lemmer.lemmatize(word) for word in data[i].split()])\n",
    "    \n",
    "    # Return data\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=2)]: Done 240 out of 240 | elapsed: 12.0min finished\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results---\n",
      "Best Score: 0.7083264666317374\n",
      "c__alpha: 0.3\n",
      "t__use_idf: True\n",
      "v__lowercase: True\n",
      "v__ngram_range: (1, 1)\n",
      "-- Training data --\n",
      "Accuracy: 89.37\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.95      0.74      0.83       480\n",
      "           comp.graphics       0.93      0.89      0.91       584\n",
      " comp.os.ms-windows.misc       0.92      0.87      0.89       591\n",
      "comp.sys.ibm.pc.hardware       0.83      0.93      0.88       590\n",
      "   comp.sys.mac.hardware       0.96      0.89      0.92       578\n",
      "          comp.windows.x       0.94      0.96      0.95       593\n",
      "            misc.forsale       0.96      0.88      0.91       585\n",
      "               rec.autos       0.95      0.88      0.92       594\n",
      "         rec.motorcycles       0.98      0.93      0.96       598\n",
      "      rec.sport.baseball       0.99      0.93      0.96       597\n",
      "        rec.sport.hockey       0.65      0.97      0.78       600\n",
      "               sci.crypt       0.90      0.95      0.92       595\n",
      "         sci.electronics       0.95      0.89      0.92       591\n",
      "                 sci.med       0.98      0.95      0.96       594\n",
      "               sci.space       0.97      0.95      0.96       593\n",
      "  soc.religion.christian       0.64      0.98      0.77       599\n",
      "      talk.politics.guns       0.88      0.95      0.91       546\n",
      "   talk.politics.mideast       0.94      0.94      0.94       564\n",
      "      talk.politics.misc       0.98      0.86      0.91       465\n",
      "      talk.religion.misc       1.00      0.30      0.46       377\n",
      "\n",
      "                accuracy                           0.89     11314\n",
      "               macro avg       0.92      0.88      0.88     11314\n",
      "            weighted avg       0.91      0.89      0.89     11314\n",
      "\n",
      "\n",
      "-- 10-fold CV --\n",
      "Accuracy: 71.67\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.81      0.33      0.47       480\n",
      "           comp.graphics       0.72      0.67      0.69       584\n",
      " comp.os.ms-windows.misc       0.74      0.60      0.66       591\n",
      "comp.sys.ibm.pc.hardware       0.61      0.74      0.67       590\n",
      "   comp.sys.mac.hardware       0.78      0.71      0.74       578\n",
      "          comp.windows.x       0.80      0.85      0.82       593\n",
      "            misc.forsale       0.82      0.67      0.73       585\n",
      "               rec.autos       0.81      0.72      0.76       594\n",
      "         rec.motorcycles       0.81      0.73      0.77       598\n",
      "      rec.sport.baseball       0.92      0.82      0.86       597\n",
      "        rec.sport.hockey       0.59      0.90      0.71       600\n",
      "               sci.crypt       0.64      0.86      0.74       595\n",
      "         sci.electronics       0.78      0.69      0.73       591\n",
      "                 sci.med       0.87      0.81      0.84       594\n",
      "               sci.space       0.83      0.78      0.80       593\n",
      "  soc.religion.christian       0.43      0.94      0.59       599\n",
      "      talk.politics.guns       0.68      0.81      0.74       546\n",
      "   talk.politics.mideast       0.80      0.82      0.81       564\n",
      "      talk.politics.misc       0.85      0.49      0.62       465\n",
      "      talk.religion.misc       0.59      0.04      0.08       377\n",
      "\n",
      "                accuracy                           0.72     11314\n",
      "               macro avg       0.74      0.70      0.69     11314\n",
      "            weighted avg       0.75      0.72      0.71     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import Libraries\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "\n",
    "import common\n",
    "\n",
    "\n",
    "# Visualize dataset\n",
    "\n",
    "def visualize_dataset(ds):\n",
    "    \n",
    "    # Print dataset\n",
    "    \n",
    "    #for i in range(5):\n",
    "    #    print(ds.data[i])\n",
    "    #print(ds.target_names)\n",
    "    \n",
    "    print('--- Information ---')\n",
    "    print('Number of articles: ' + str(len(ds.data)))\n",
    "    print('Number of categories: ' + str(len(ds.target_names)))\n",
    "    \n",
    "    \n",
    "    # count number of articles in each category\n",
    "    plot_X = np.arange(20, dtype=np.int16)\n",
    "    plot_Y = np.zeros(20)\n",
    "    for i in range(len(ds.data)):\n",
    "        plot_Y[ds.target[i]] += 1\n",
    "        \n",
    "    print('\\n--- Class Distribution ---')\n",
    "    for i in range(len(plot_X)):\n",
    "        print('{0}: {1:.0f}'.format(ds.target_names[plot_X[i]], plot_Y[i]))\n",
    "\n",
    "    # Plot the balance of the dataset\n",
    "\n",
    "    figure = plt.figure(figsize = (16, 10))\n",
    "    figure.suptitle('Balance of data set', fontsize=16)\n",
    "    plt.bar(plot_X, plot_Y, align='center', color='rgbkymc')\n",
    "    plt.xticks(plot_X, ds.target_names, rotation=25, horizontalalignment='right')\n",
    "    plt.show()\n",
    "    plt.savefig('C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\20NewsGroupsBalance.png')\n",
    "\n",
    "\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "\n",
    "def grid_search(train):\n",
    "    \n",
    "    # Create a pipeline\n",
    "    clf_pipeline = sklearn.pipeline.Pipeline([\n",
    "        ('v', sklearn.feature_extraction.text.CountVectorizer(strip_accents='ascii', stop_words='english')),\n",
    "        ('t', sklearn.feature_extraction.text.TfidfTransformer()),\n",
    "        ('c', sklearn.naive_bayes.MultinomialNB(fit_prior=True, class_prior=None))\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Set parameters (name in pipeline + name of parameter)\n",
    "    parameters = {\n",
    "        'v__ngram_range': [(1,1), (1,2), (1,3), (1,4)],\n",
    "        'v__lowercase': (True, False),\n",
    "        't__use_idf': (True, False),\n",
    "        'c__alpha': (0.3, 0.6, 1.0)}\n",
    "    \n",
    "    \n",
    "    # Create a grid search classifier\n",
    "    gs_classifier = sklearn.model_selection.GridSearchCV(clf_pipeline, parameters, cv=5, iid=False, n_jobs=2, scoring='accuracy', verbose=1)\n",
    "    \n",
    "     # Start a search (Warning: takes a long time if the whole dataset is used)\n",
    "    # Slice: (train.data[:4000], train.target[:4000])\n",
    "    gs_classifier = gs_classifier.fit(train.data, train.target)\n",
    "    \n",
    "    \n",
    "    # Print results\n",
    "    print('--- Results---')\n",
    "    print('Best Score: ' + str(gs_classifier.best_score_))\n",
    "    for name in sorted(parameters.keys()):\n",
    "        print('{0}: {1}'.format(name, gs_classifier.best_params_[name]))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Train and evaluate a model\n",
    "\n",
    "def train_and_evaluate(train):\n",
    "    \n",
    "    # Convert to bag of words\n",
    "    count_vect = sklearn.feature_extraction.text.CountVectorizer(strip_accents='ascii', stop_words='english', lowercase=True, ngram_range=(1,1))\n",
    "    X = count_vect.fit_transform(train.data)\n",
    "    \n",
    "    \n",
    "    # Convert from occurrences to frequencies\n",
    "    # Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.\n",
    "    # To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called tf for Term Frequencies.\n",
    "    transformer = sklearn.feature_extraction.text.TfidfTransformer()\n",
    "    X = transformer.fit_transform(X)\n",
    "    \n",
    "    \n",
    "    # Create a model\n",
    "    model = sklearn.naive_bayes.MultinomialNB(alpha=0.3, fit_prior=True, class_prior=None)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X, train.target)\n",
    "    \n",
    "    # Save models\n",
    "    joblib.dump(count_vect, 'C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\vectorizer.jbl') \n",
    "    joblib.dump(transformer,'C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\transformer.jbl')\n",
    "    joblib.dump(model, 'C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\model.jbl')\n",
    "    \n",
    "    \n",
    "    # Evaluate on training data\n",
    "    print('-- Training data --')\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(train.target, predictions)\n",
    "    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(sklearn.metrics.classification_report(train.target, predictions, target_names=train.target_names))\n",
    "    print('')\n",
    "    \n",
    "    # Evaluate with 10-fold CV\n",
    "    print('-- 10-fold CV --')\n",
    "    predictions = sklearn.model_selection.cross_val_predict(model, X, train.target, cv=10)\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(train.target, predictions)\n",
    "    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "    print('Classification Report:')\n",
    "    print(sklearn.metrics.classification_report(train.target, predictions, target_names=train.target_names))\n",
    "\n",
    "    \n",
    "    \n",
    "# The main entry point for this module\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Load train dataset\n",
    "    # Load text files with categories as subfolder names\n",
    "    # Individual samples are assumed to be files stored a two levels folder structure\n",
    "    # The folder names are used as supervised signal label names. The individual file names are not important.\n",
    "    \n",
    "    train = sklearn.datasets.load_files('C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\20news-bydate\\\\20news-bydate-train', shuffle=False, load_content=True, encoding='latin1')\n",
    "     \n",
    "    # Visualize dataset\n",
    "    #visualize_dataset(train)\n",
    "    \n",
    "    # Preprocess data\n",
    "    train.data = preprocess_data(train.data)\n",
    "    \n",
    "    # Print cleaned data\n",
    "    #print(train.data[0])\n",
    "    \n",
    "     # Grid search\n",
    "    grid_search(train)\n",
    "    \n",
    "     # Train and evaluate\n",
    "    train_and_evaluate(train)\n",
    "    \n",
    "\n",
    "# Tell python to run main method\n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Results --\n",
      "Accuracy: 67.83\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.24      0.36       319\n",
      "           comp.graphics       0.66      0.66      0.66       389\n",
      " comp.os.ms-windows.misc       0.72      0.54      0.62       394\n",
      "comp.sys.ibm.pc.hardware       0.59      0.72      0.65       392\n",
      "   comp.sys.mac.hardware       0.75      0.68      0.71       385\n",
      "          comp.windows.x       0.80      0.76      0.78       395\n",
      "            misc.forsale       0.82      0.68      0.74       390\n",
      "               rec.autos       0.83      0.74      0.78       396\n",
      "         rec.motorcycles       0.83      0.73      0.78       398\n",
      "      rec.sport.baseball       0.94      0.81      0.87       397\n",
      "        rec.sport.hockey       0.59      0.94      0.72       399\n",
      "               sci.crypt       0.60      0.80      0.69       396\n",
      "         sci.electronics       0.69      0.55      0.61       393\n",
      "                 sci.med       0.86      0.78      0.82       396\n",
      "               sci.space       0.76      0.77      0.77       394\n",
      "  soc.religion.christian       0.39      0.92      0.55       398\n",
      "      talk.politics.guns       0.54      0.72      0.62       364\n",
      "   talk.politics.mideast       0.80      0.80      0.80       376\n",
      "      talk.politics.misc       0.80      0.34      0.48       310\n",
      "      talk.religion.misc       0.75      0.01      0.02       251\n",
      "\n",
      "                accuracy                           0.68      7532\n",
      "               macro avg       0.72      0.66      0.65      7532\n",
      "            weighted avg       0.72      0.68      0.67      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import joblib\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.metrics\n",
    "\n",
    "import common\n",
    "\n",
    "\n",
    "\n",
    "# Test and evaluate a model\n",
    "\n",
    "def test_and_evaluate(test):\n",
    "    \n",
    "    # Save models\n",
    "    vectorizer = joblib.load('C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\vectorizer.jbl') \n",
    "    transformer = joblib.load('C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\transformer.jbl')\n",
    "    model = joblib.load('C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\model.jbl')\n",
    "    \n",
    "    # Convert to bag of words\n",
    "    X = vectorizer.transform(test.data)\n",
    "    \n",
    "    # Convert from occurrences to frequencies\n",
    "    X = transformer.transform(X)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    # Print results\n",
    "    print('-- Results --')\n",
    "    accuracy = sklearn.metrics.accuracy_score(test.target, predictions)\n",
    "    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "    print('Classification Report:')\n",
    "    print(sklearn.metrics.classification_report(test.target, predictions, target_names=test.target_names))\n",
    "\n",
    "\n",
    "\n",
    "# The main entry point for this module\n",
    "def main():\n",
    "    \n",
    "    \n",
    "    # Load test dataset\n",
    "    # Load text files with categories as subfolder names\n",
    "    # Individual samples are assumed to be files stored a two levels folder structure\n",
    "    # The folder names are used as supervised signal label names. The individual file names are not important.\n",
    "\n",
    "    test = sklearn.datasets.load_files(r\"C:\\\\Users\\\\User\\\\Jupyter Notebooks\\\\NBNewsGroups\\\\20news-bydate\\20news-bydate-test\", shuffle=False, load_content=True, encoding='latin1')\n",
    "    \n",
    "    # Preprocess data\n",
    "    test.data = preprocess_data(test.data)\n",
    "    \n",
    "    # Print cleaned data\n",
    "    #print(test.data[0])\n",
    "    \n",
    "    # Test and evaluate\n",
    "    test_and_evaluate(test)\n",
    "    \n",
    "# Tell python to run main method\n",
    "if __name__ == \"__main__\": main()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
